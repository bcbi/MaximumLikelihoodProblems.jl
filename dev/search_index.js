var documenterSearchIndex = {"docs":
[{"location":"logistic_regression/#","page":"Logistic regression","title":"Logistic regression","text":"EditURL = \"https://github.com/bcbi/MaximumLikelihoodProblems.jl/blob/master/examples/logistic_regression.jl\"","category":"page"},{"location":"logistic_regression/#Logistic-regression-1","page":"Logistic regression","title":"Logistic regression","text":"","category":"section"},{"location":"logistic_regression/#","page":"Logistic regression","title":"Logistic regression","text":"import MaximumLikelihoodProblems\n\nimport Distributions\nimport ForwardDiff\nimport LogDensityProblems\nimport StatsFuns\nimport TransformVariables\n\nstruct LogisticRegression{Ty, TX}\n    y::Ty\n    X::TX\nend\n\nfunction (problem::LogisticRegression)(θ)\n    y = problem.y\n    X = problem.X\n\n    β = θ.β\n\n    η = X * β\n    μ = StatsFuns.logistic.(η)\n    log_likelihood = sum(Distributions.logpdf.(Distributions.Bernoulli.(μ), y))\n    return log_likelihood\nend\n\nN = 10_000\n\n# the first column (the column of all ones) is the intercept\nX = hcat(ones(N), randn(N))\n\nsize_β = (2,)\nβ_true = [1.0, 2.0]\nη_true = X * β_true\nμ_true = StatsFuns.logistic.(η_true)\ny = rand.(Distributions.Bernoulli.(μ_true))\n\nproblem = LogisticRegression(y, X)\ntransformation = TransformVariables.as((β = TransformVariables.as(Array, size_β), ))\ntransformed_problem = LogDensityProblems.TransformedLogDensity(transformation,\n                                                               problem)\ntransformed_gradient_problem = LogDensityProblems.ADgradient(:ForwardDiff,\n                                                             transformed_problem)\n\nβ_hat_initial_guess = zeros(size_β)\nθ_hat_initial = (; β = β_hat_initial_guess)","category":"page"},{"location":"logistic_regression/#","page":"Logistic regression","title":"Logistic regression","text":"θ_hat:","category":"page"},{"location":"logistic_regression/#","page":"Logistic regression","title":"Logistic regression","text":"θ_hat = MaximumLikelihoodProblems.fit(transformed_gradient_problem,\n                                      θ_hat_initial)","category":"page"},{"location":"logistic_regression/#","page":"Logistic regression","title":"Logistic regression","text":"β_hat:","category":"page"},{"location":"logistic_regression/#","page":"Logistic regression","title":"Logistic regression","text":"β_hat = θ_hat[:β]","category":"page"},{"location":"logistic_regression/#","page":"Logistic regression","title":"Logistic regression","text":"","category":"page"},{"location":"logistic_regression/#","page":"Logistic regression","title":"Logistic regression","text":"This page was generated using Literate.jl.","category":"page"},{"location":"api_public/#Public-API-1","page":"Public API","title":"Public API","text":"","category":"section"},{"location":"api_public/#","page":"Public API","title":"Public API","text":"MaximumLikelihoodProblems.fit","category":"page"},{"location":"api_public/#MaximumLikelihoodProblems.fit","page":"Public API","title":"MaximumLikelihoodProblems.fit","text":"fit(transformed_gradient_problem, theta_hat_initial; kwargs...)\n\nArguments\n\ntransformed_gradient_problem\ntheta_hat_initial\n\nKeyword Arguments\n\nlearning_rate. Default value: 0.0001\nmax_iterations. Default value: 1000000\nshow_progress_meter. Default value: true\nthrow_convergence_exception. Default value: true\ntolerance. Default value: 1.0e-10\n\nSee the documentation for fully worked-out examples.\n\n\n\n\n\n","category":"function"},{"location":"multinomial_logistic_regression/#","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"EditURL = \"https://github.com/bcbi/MaximumLikelihoodProblems.jl/blob/master/examples/multinomial_logistic_regression.jl\"","category":"page"},{"location":"multinomial_logistic_regression/#Multinomial-logistic-regression-1","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"","category":"section"},{"location":"multinomial_logistic_regression/#","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"import MaximumLikelihoodProblems\n\nimport Distributions\nimport ForwardDiff\nimport LogDensityProblems\nimport NNlib\nimport TransformVariables\n\nstruct MultinomialLogisticRegression{Ty, TX}\n    y::Ty\n    X::TX\nend\n\nfunction (problem::MultinomialLogisticRegression)(θ)\n    y = problem.y\n    X = problem.X\n\n    β = θ.β\n\n    num_rows = size(X, 1)\n    num_covariates = size(β, 1) ## `size(β, 1)` is equal to `size(X, 2)`\n    num_classes = size(β, 2) + 1\n\n    # the first column of all zeros corresponds to the base class\n    # i.e. the coefficient β₀ for the base class is always fixed to be zero\n    β_with_base_class = hcat(zeros(num_covariates), β)\n    η = X * β_with_base_class\n\n    μ = NNlib.softmax(η; dims=2)\n    log_likelihood = sum([Distributions.logpdf(Distributions.Multinomial(1, μ[i, :]), y[i, :]) for i = 1:num_rows])\n    return log_likelihood\nend\n\nN = 10_000\n\n# the first column (the column of all ones) is the intercept\nX = hcat(ones(N), randn(N))\n\nsize_β = (2, 3)\nβ_true = [1.0 2.0 3.0; 4.0 5.0 6.0]\nnum_covariates = size(β_true, 1)\nβ_true_with_base_class = hcat(zeros(num_covariates), β_true)\nη_true = X * β_true_with_base_class\nμ_true = NNlib.softmax(η_true; dims=2)\ny = vcat([rand(Distributions.Multinomial(1, μ_true[i,:]))' for i in 1:N]...)\n\nproblem = MultinomialLogisticRegression(y, X)\ntransformation = TransformVariables.as((β = TransformVariables.as(Array, size_β), ))\ntransformed_problem = LogDensityProblems.TransformedLogDensity(transformation,\n                                                               problem)\ntransformed_gradient_problem = LogDensityProblems.ADgradient(:ForwardDiff,\n                                                             transformed_problem)\n\nβ_hat_initial_guess = zeros(size_β)\nθ_hat_initial = (; β = β_hat_initial_guess)","category":"page"},{"location":"multinomial_logistic_regression/#","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"θ_hat:","category":"page"},{"location":"multinomial_logistic_regression/#","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"θ_hat = MaximumLikelihoodProblems.fit(transformed_gradient_problem,\n                                      θ_hat_initial;\n                                      show_progress_meter = false)","category":"page"},{"location":"multinomial_logistic_regression/#","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"β_hat:","category":"page"},{"location":"multinomial_logistic_regression/#","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"β_hat = θ_hat[:β]","category":"page"},{"location":"multinomial_logistic_regression/#","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"βhatwithbaseclass:","category":"page"},{"location":"multinomial_logistic_regression/#","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"num_covariates = size(β_hat, 1)\nβ_hat_with_base_class = hcat(zeros(num_covariates), β_hat)","category":"page"},{"location":"multinomial_logistic_regression/#","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"","category":"page"},{"location":"multinomial_logistic_regression/#","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"This page was generated using Literate.jl.","category":"page"},{"location":"#MaximumLikelihoodProblems.jl-1","page":"Home","title":"MaximumLikelihoodProblems.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"This is the documentation for MaximumLikelihoodProblems.jl.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"MaximumLikelihoodProblems provides a framework for formulating likelihood problems and solving them with maximum likelihood estimation (MLE).","category":"page"},{"location":"linear_regression/#","page":"Linear regression","title":"Linear regression","text":"EditURL = \"https://github.com/bcbi/MaximumLikelihoodProblems.jl/blob/master/examples/linear_regression.jl\"","category":"page"},{"location":"linear_regression/#Linear-regression-1","page":"Linear regression","title":"Linear regression","text":"","category":"section"},{"location":"linear_regression/#","page":"Linear regression","title":"Linear regression","text":"import MaximumLikelihoodProblems\n\nimport Distributions\nimport ForwardDiff\nimport LogDensityProblems\nimport TransformVariables\n\nstruct LinearRegression{Ty, TX}\n    y::Ty\n    X::TX\nend\n\nfunction (problem::LinearRegression)(θ)\n    y = problem.y\n    X = problem.X\n\n    β = θ.β\n    σ = θ.σ\n\n    η = X * β\n    μ = η\n    ε = y - μ\n\n    # these two lines are equivalent:\n    # log_likelihood = Distributions.loglikelihood(Distributions.Normal(0, σ), ε)\n    # log_likelihood = sum(Distributions.logpdf.(Distributions.Normal(0, σ), ε))\n\n    log_likelihood = sum(Distributions.logpdf.(Distributions.Normal(0, σ), ε))\n    return log_likelihood\nend\n\nN = 10_000\n\n# the first column (the column of all ones) is the intercept\nX = hcat(ones(N), randn(N), randn(N))\n\nsize_β = (3,)\nβ_true = [1.0, 2.0, -1.0]\nσ_true = 0.5\nη_true = X * β_true\nμ_true = η_true\nε_true = randn(N) .* σ_true\ny = μ_true + ε_true\n\nfunction generate_problem_transformation(p::LinearRegression)\n    return TransformVariables.as((β = TransformVariables.as(Array, size(p.X, 2)),\n                                  σ = TransformVariables.asℝ₊))\nend\n\nproblem = LinearRegression(y, X)\ntransformation = generate_problem_transformation(problem)\ntransformed_problem = LogDensityProblems.TransformedLogDensity(transformation,\n                                                               problem)\ntransformed_gradient_problem = LogDensityProblems.ADgradient(:ForwardDiff,\n                                                             transformed_problem)\n\nβ_hat_initial_guess = zeros(size_β)\nσ_hat_initial_guess = 1.0\n\nθ_hat_initial = (; β = β_hat_initial_guess,\n                   σ = σ_hat_initial_guess)","category":"page"},{"location":"linear_regression/#","page":"Linear regression","title":"Linear regression","text":"θ_hat:","category":"page"},{"location":"linear_regression/#","page":"Linear regression","title":"Linear regression","text":"θ_hat = MaximumLikelihoodProblems.fit(transformed_gradient_problem,\n                                      θ_hat_initial;\n                                      learning_rate = 1e-6)","category":"page"},{"location":"linear_regression/#","page":"Linear regression","title":"Linear regression","text":"β_hat:","category":"page"},{"location":"linear_regression/#","page":"Linear regression","title":"Linear regression","text":"β_hat = θ_hat[:β]","category":"page"},{"location":"linear_regression/#","page":"Linear regression","title":"Linear regression","text":"σ_hat:","category":"page"},{"location":"linear_regression/#","page":"Linear regression","title":"Linear regression","text":"σ_hat = θ_hat[:σ]","category":"page"},{"location":"linear_regression/#","page":"Linear regression","title":"Linear regression","text":"","category":"page"},{"location":"linear_regression/#","page":"Linear regression","title":"Linear regression","text":"This page was generated using Literate.jl.","category":"page"}]
}
